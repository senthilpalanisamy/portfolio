---
layout: default
modal-id: 1
date: 2019-12-10
img: baxterbuilder.gif
alt: image-alt
project-date: April 2014
description: Uses the robot's right hand to observe the baseplate, spot a red brick and determine its position for pickup Detects all AR frames visible in the camera's field of view. Then pre-calibrated intrinsic camera parameters are used to do inverse projection to get the 3D location of a point corresponding to a pixel location. The 3D point corresponding to the pixel is determined in multiple AR frames and then these points are converted to the baxter world frame representation. Then we get muliple points in world frame that correspond to the same pixel but obtained using different AR frames as reference. The median of all those points is found out and that point is taken to be the true 3D location corresponding to a pixel in the image. Reason why we use multiple AR frames when one should be sufficient in theory - Sometimes AR tags are affected by lighting and their 3D pose with respect to the camera oscillates. Even worse sometimes, they are not detected. Using multiple AR tags this way increases both the roboustness and the precision of the system. We were able to locate points within +/- 1 cm accuracy with this process. We then use move it to move baxter's left ram to the block pickup location, pickup the block by controlling gripper through baxter's native libraties and then use move it again to move the blocks to a pre-configured goal location. This process is repeated until 3 blocks are placed to construct a small pyramid. <iframe width="560" height="315" src="https://www.youtube.com/embed/mz1FwBR94og" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> 
title: Baxter, the lego-builder 

---
